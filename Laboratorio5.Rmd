---
title: "Laboratorio 5"
output:
  html_notebook: default
  pdf_document: default
---

## Descripción de los datos
* _Blogs_: El tamaño de estos datos son de aproximadamente  210.2 MB, proviene de un blog estadounidense. Además, el tipo de corpus es monolingüe, ya que el texto se encuentra escrito solamente en inglés; se encuentran emoticones, tales como corazones y caras escritas mediante los signos ortográficos. Aparecen muchas veces los signos de exclamación y se observa una escritura de narración para un público abierto. 
* _Twitter_: El tamaño de estos datos son de aproximadamente 167.1 MB, proviene de la red social twitter, donde el contenido es especificamente estadounidense. Además, el tipo de corpus es monolingüe, ya que el texto se encuentra escrito solamente en inglés; se encuentran emoticones, tales como corazones y caras escritas mediante los signos otográficos, signos de interrogación y exclamación, hashtags # y menciones @.
* _News_: El tamaño de los datos es aproximadamente de 205.8 MB, proviene de un noticiero en línea estadounidense. El tipo de corpus es monolingüe, ya que el texto se encuentra escrito solamente en inglés. No se observan emoticones pero sí links y caracteres especiales, así como los signos dólar.


Los paquetes que se usaron para este laboratorio fueron los siguientes:
```{r}
library("readr")
library("tm")
library("SnowballC")

```


Ahora, se importan los datos, se leen y se crean samples aleatorias con 5% de las observaciones para cada texto
```{r}

#C:/Users/smayr/Documents/Tercer año/Semestre 6/Data Science/Laboratorio 5
# /Users/quiebres/Desktop/Texts
texto <- VCorpus(DirSource("/Users/quiebres/Desktop/Texts"), readerControl = list(language = "en"))
set.seed(3)
porciento <- 0.05
texto[[1]]$content <- sample(texto[[1]]$content,length(texto[[1]]$content)*porciento)
texto[[2]]$content <- sample(texto[[2]]$content,length(texto[[2]]$content)*porciento)
texto[[3]]$content <- sample(texto[[3]]$content,length(texto[[3]]$content)*porciento)



blog <- Corpus(VectorSource(texto[[1]]$content))

news <- Corpus(VectorSource(texto[[2]]$content))

twitter <- Corpus(VectorSource(texto[[3]]$content))



```

Se le pide un summary a los textos de blog, news y twitter
```{r}
# No sé como hacerlo
```
Se elemininan las puntuaciones de los textos
```{r}
blog <- tm_map(blog,removePunctuation)

for (j in seq(blog)) {
    blog[[j]] <- gsub("/", " ", blog[[j]])
    blog[[j]] <- gsub("@", " ", blog[[j]])
    blog[[j]] <- gsub("\\|", " ", blog[[j]])
}

news <- tm_map(news,removePunctuation)

for (j in seq(news)) {
    news[[j]] <- gsub("/", " ", news[[j]])
    news[[j]] <- gsub("@", " ", news[[j]])
    news[[j]] <- gsub("\\|", " ", news[[j]])
}

twitter <- tm_map(twitter, removePunctuation)

for (j in seq()) {
    twitter[[j]] <- gsub("/", " ", twitter[[j]])
    twitter[[j]] <- gsub("@", " ", twitter[[j]])
    twitter[[j]] <- gsub("\\|", " ", twitter[[j]])
    twitter[[j]] <- gsub("#", " ", twitter[[j]])
}

```
Se cambian las letras a minúsculas
```{r}
blog <- tm_map(blog, tolower)

news <- tm_map(news,tolower)

twitter <- tm_map(twitter, tolower)

```
Se elminan las stopwords
```{r}
blog <- tm_map(blog, removeWords, stopwords("english"))

news <- tm_map(news, removeWords, stopwords("english"))

twitter <- tm_map(twitter, removeWords, stopwords("english"))

```